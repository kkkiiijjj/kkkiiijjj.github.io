<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  
  <title>2023-12-6 | Forforevery</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  <meta name="description" content="epoch与batch size一个epoch 指的是把所有训练数据丢进神经网络一次。 由于训练数据常常太大了，得慢慢来，所以我们常常把训练数据分成好几等份，分完之后每份数据的数量就是 batch size，而几等份的这个几就是iteration。 总结一下， epoch指的是次数，epoch &#x3D; 10 指的是把整个数据集丢进神经网络训练10次。 batch size 指的是数据的个数，">
<meta property="og:type" content="article">
<meta property="og:title" content="2023-12-6">
<meta property="og:url" content="https://kkkiiijjj.github.io/2023/12/06/2023-12-6/index.html">
<meta property="og:site_name" content="Forforevery">
<meta property="og:description" content="epoch与batch size一个epoch 指的是把所有训练数据丢进神经网络一次。 由于训练数据常常太大了，得慢慢来，所以我们常常把训练数据分成好几等份，分完之后每份数据的数量就是 batch size，而几等份的这个几就是iteration。 总结一下， epoch指的是次数，epoch &#x3D; 10 指的是把整个数据集丢进神经网络训练10次。 batch size 指的是数据的个数，">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://kkkiiijjj.github.io/image-7.png">
<meta property="og:image" content="https://kkkiiijjj.github.io/image-8.png">
<meta property="og:image" content="https://kkkiiijjj.github.io/image-9.png">
<meta property="og:image" content="https://kkkiiijjj.github.io/image-10.png">
<meta property="og:image" content="https://kkkiiijjj.github.io/image-11.png">
<meta property="og:image" content="https://kkkiiijjj.github.io/image-12.png">
<meta property="og:image" content="https://kkkiiijjj.github.io/image-13.png">
<meta property="article:published_time" content="2023-12-06T02:54:08.000Z">
<meta property="article:modified_time" content="2023-12-21T13:19:49.045Z">
<meta property="article:author" content="Wang">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://kkkiiijjj.github.io/image-7.png">
  
    <link rel="alternate" href="/atom.xml" title="Forforevery" type="application/atom+xml">
  
  
    <link rel="shortcut icon" href="/favicon.png">
  
  
    
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/typeface-source-code-pro@0.0.71/index.min.css">

  
  
<link rel="stylesheet" href="/css/style.css">

  
    
<link rel="stylesheet" href="/fancybox/jquery.fancybox.min.css">

  
  
<meta name="generator" content="Hexo 6.3.0"></head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">Forforevery</a>
      </h1>
      
        <h2 id="subtitle-wrap">
          <a href="/" id="subtitle">my blog</a>
        </h2>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"><span class="fa fa-bars"></span></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
        
          <a class="nav-icon" href="/atom.xml" title="RSS Feed"><span class="fa fa-rss"></span></a>
        
        <a class="nav-icon nav-search-btn" title="Search"><span class="fa fa-search"></span></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="https://kkkiiijjj.github.io"></form>
      </div>
    </div>
  </div>
</header>

      <div class="outer">
        <section id="main"><article id="post-2023-12-6" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2023/12/06/2023-12-6/" class="article-date">
  <time class="dt-published" datetime="2023-12-06T02:54:08.000Z" itemprop="datePublished">2023-12-06</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="p-name article-title" itemprop="headline name">
      2023-12-6
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <h2 id="epoch与batch-size"><a href="#epoch与batch-size" class="headerlink" title="epoch与batch size"></a>epoch与batch size</h2><p>一个epoch 指的是把所有训练数据丢进神经网络一次。</p>
<p>由于训练数据常常太大了，得慢慢来，所以我们常常把训练数据分成好几等份，分完之后每份数据的数量就是 batch size，而几等份的这个几就是iteration。</p>
<p>总结一下，</p>
<p>epoch指的是次数，epoch &#x3D; 10 指的是把整个数据集丢进神经网络训练10次。</p>
<p>batch size 指的是数据的个数，batch size &#x3D; 10 指的是每次扔进神经网络训练的数据是10个。</p>
<p>iteration同样指的是次数，iteration &#x3D; 10 指的是把整个数据集分成10次扔进神经网络。<br>假如有100个训练数据，epoch &#x3D; 10, batch size &#x3D; 5, iteration &#x3D; ?<br>interation&#x3D;100&#x2F;5&#x3D;20.<br><img src="/image-7.png" alt="Alt text"></p>
<hr>
<p>机器学习：给数据——&gt;定义模型——&gt;训练&#x2F;<br>神图，偷了&#x2F;<br><img src="/image-8.png" alt="Alt text"><br>mlp是ANN中的一种<br>mxnet与pytorth相似<br><a target="_blank" rel="noopener" href="https://v.subnice.top/api/v1/client/subscribe?token=b570429dacabcd3b06b59c513bfdd745">https://v.subnice.top/api/v1/client/subscribe?token=b570429dacabcd3b06b59c513bfdd745</a><br>成功搭了个梯子(≧∇≦)ﾉ</p>
<p>我还是一点点慢慢学吧，代码看不懂</p>
<h2 id="今天先学数据预处理"><a href="#今天先学数据预处理" class="headerlink" title="今天先学数据预处理"></a>今天先学数据预处理</h2><p>​ 数据预处理的主要内容包括：数据清洗、数据集成、数据变换和数据规约<br><strong>csv</strong>:一种用逗号分隔数据的文件<br><strong>os</strong>:是“operating system”的缩写<br><strong>os.makedirs</strong>(name, mode&#x3D;0o777, exist_ok&#x3D;False)<br><em>作用</em>:<br>用来创建多层目录（单层请用os.mkdir）<br><em>参数说明</em>：<br>name：你想创建的目录名<br>mode：要为目录设置的权限数字模式，默认的模式为 0o777 (八进制)<br>exist_ok：是否在目录存在时触发异常。如果exist_ok为False（默认值），则在目标目录已存在的情况下触发FileExistsError异常；如果exist_ok为True，则在目标目录已存在的情况下不会触发FileExistsError异常</p>
<p><strong>os.path.join</strong>(path1[, path2[, …]])	把目录和文件名合成一个路径<br><strong>iloc[]函数</strong>，属于pandas库，全称为index location<br>例子：</p>
<table>
<thead>
<tr>
<th></th>
<th>姓名（列索引10）</th>
<th>班级（列索引1）</th>
<th>分数（列索引2）</th>
</tr>
</thead>
<tbody><tr>
<td>0（行索引0）</td>
<td>小明</td>
<td>302</td>
<td>87</td>
</tr>
<tr>
<td>1（行索引1）</td>
<td>小王</td>
<td>303</td>
<td>95</td>
</tr>
<tr>
<td>2（行索引2）</td>
<td>小方</td>
<td>303</td>
<td>100</td>
</tr>
</tbody></table>
<p>1.iloc[a,b]:取行索引为a列索引为b的数据。<br>import pandas<br>df &#x3D; pandas.read_csv(‘a.csv’)<br>print(df.iloc[1,2])<br>Out：95<br>iloc[a:b,c]:取行索引从a到b-1，列索引为c的数据。注意：在iloc中a:b是左到右不到的</p>
<h2 id="get-dummies"><a href="#get-dummies" class="headerlink" title="get_dummies"></a>get_dummies</h2><p>是利用pandas实现one hot encode的方式。<br>例子：<br>import pandas as pd<br>df &#x3D; pd.DataFrame([<br>            [‘green’ , ‘A’],<br>            [‘red’   , ‘B’],<br>            [‘blue’  , ‘A’]])  </p>
<p>df.columns &#x3D; [‘color’,  ‘class’]<br>pd.get_dummies(df) <br>get_dummies 前：<br><img src="/image-9.png" alt="Alt text"><br>get_dummies 后：<br><img src="/image-10.png" alt="Alt text"><br>上述执行完以后再打印df 出来的还是get_dummies 前的图，因为你没有写df &#x3D; pd.get_dummies(df)</p>
<p>可以对指定列进行get_dummies<br>pd.get_dummies(df.color)<br><img src="/image-11.png" alt="Alt text"><br>将指定列进行get_dummies 后合并到元数据中<br>df &#x3D; df.join(pd.get_dummies(df.color))<br><img src="/image-12.png" alt="Alt text">\</p>
<h2 id="范数："><a href="#范数：" class="headerlink" title="范数："></a>范数：</h2><p>欧几里得距离是一个L2范数：假设n维向量x中的元素是x1,…,xn，其L2范数是向量元素平方和的平方根<br>$||x||<em>2&#x3D;\sqrt{\sum</em>{i&#x3D;1}^nx_i^2}$<br>其中，在L2范数中常常省略下标2，也就是说∥x∥等同于∥x∥2。在代码中，我们可以按如下方式计算向量的L2范<br>数。<br>u &#x3D; np.array([3,-4])<br> np.linalg.norm(u)</p>
<p>深度学习中更经常地使用L2范数的平方，也会经常遇到L1范数，它表示为向量元素的绝对值之和：<br>$||x||<em>1&#x3D;\sum</em>{i&#x3D;1}^n|x_i|$<br>与L2范数相比，L1范数受异常值的影响较小。为了计算L1范数，我们将绝对值函数和按元素求和组合起来。<br>np.abs(u).sum()<br> array(7.)<br> %.5f：表示按浮点数输出，小数点后面取5位<br> <strong>SVG</strong> 意为可缩放矢量图形（Scalable Vector Graphics）。<br> multinomial distribution:多项式分布<br> binomial:二项式</p>
<p> 为了知道模块中可以调用哪些函数和类，可以调用dir函数。<br>  print(dir(np.random))<br> 有关如何使用给定函数或类的更具体说明，可以调用help函数<br> help(np.ones)</p>
<h2 id="线性模型"><a href="#线性模型" class="headerlink" title="线性模型"></a>线性模型</h2><p> ˆ<br> y &#x3D;Xw+b<br> X的每一行是一个样本，每一列是一种特征。权重放到向量w∈Rd中\</p>
<h2 id="损失函数"><a href="#损失函数" class="headerlink" title="损失函数"></a>损失函数</h2><p> 回归问题中最常用的损失函数是平方误差函数。<br> <img src="/image-13.png" alt="Alt text"><br> 梯度下降（gradientdescent）的方法，这种方法几乎可以优化所有深度学习模型。<br>它通过不断地在损失函数递减的方向上更新参数来降低误差。\</p>
<h2 id="numpy-random-normal"><a href="#numpy-random-normal" class="headerlink" title="numpy.random.normal"></a>numpy.random.normal</h2><p>用例:<br>numpy.random.normal(loc&#x3D;0.0, scale&#x3D;1.0, size&#x3D;None)<br>功能:<br>从正态（高斯）分布中抽取随机样本。<br>loc：标准差<br>scale:方差<br>size:输出值的维度</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://kkkiiijjj.github.io/2023/12/06/2023-12-6/" data-id="clqa6ifbx0001bct096zib4ii" data-title="2023-12-6" class="article-share-link"><span class="fa fa-share">Share</span></a>
      
      
      
    </footer>
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2023/12/08/2023-12-8/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Newer</strong>
      <div class="article-nav-title">
        
          2023-12-8
        
      </div>
    </a>
  
  
    <a href="/2023/11/07/machine-learning/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">machine learning</div>
    </a>
  
</nav>

  
</article>


</section>
        
          <aside id="sidebar">
  
    

  
    

  
    
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/12/">December 2023</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/11/">November 2023</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/10/">October 2023</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recent Posts</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2023/12/27/torch-nn-init/">torch.nn.init</a>
          </li>
        
          <li>
            <a href="/2023/12/23/CNN/">CNN</a>
          </li>
        
          <li>
            <a href="/2023/12/21/CNN-RNN-LSTM-Transformer/">CNN RNN LSTM Transformer</a>
          </li>
        
          <li>
            <a href="/2023/12/09/2023-12-10/">2023-12-9</a>
          </li>
        
          <li>
            <a href="/2023/12/08/2023-12-8/">2023-12-8</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      
      &copy; 2023 Wang<br>
      Powered by <a href="https://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>

    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    


<script src="/js/jquery-3.6.4.min.js"></script>



  
<script src="/fancybox/jquery.fancybox.min.js"></script>




<script src="/js/script.js"></script>





  </div>
</body>
</html>